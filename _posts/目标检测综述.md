---
title: 目标检测综述 
tags: '传统方法 深度学习  RCNN YOLO等'
category: /小书匠/日记/2022-03
renderNumberedHeading: true
grammar_cjkRuby: true
---


[toc]
# 目标检测算法简介
## 目标检测问题概况
### 定义
目标检测的任务是对画面中的目标进行**定位**和**分类**。定位是指回归目标的矩形框，分类是指对目标框进行类别区分。
### 主要问题
目标检测任务主要解决以下几个问题：**目标的种类和数量**、**目标的尺寸**、**外界的干扰因素**、**特定场景任务**等；
## 目标检测算法方法概况
目标检测算法可以分为**传统目标检测算法**和**基于深度学习的目标检测算法**。其中传统的目标检测算法的主要工作集中在手工设计中低层面的特征提取算法，如**SIFT**、**HOG**特征等；基于深度学习的目标检测算法的主要功能是通过网络的设计，结合数据和loss的使用，使特征提取这个工作智能化，并将整个目标检测任务简单化。近些年随着计算领域的突破和深度学习算法架构的突破，基于深度学习的算法性能大大优于传统的方法，传统的算法已经渐渐退出历史舞台了。不过很多深度学习的方法也是基于传统算法的思路去做实现的，接下来文章会给大家介绍传统算法和深度学习算法的发展过程，让大家对目标检测算法有个大致的概念。
# 传统目标检测算法

## 传统目标检测算法架构
![传统目标检测算法流程](./images/1648355845636.png)
**候选框提取**：通过算法，选取目标候选框；**滑动窗口**、**SS算法**等；
**特征提取**：手工设计算法，提取低层特征（纹理、色彩等）、中层特征和高层语义特征，传统方法的主要工作都集中在低层和中层特征提取的算法设计上；**VJ**、**HOG特征**等；
**分类器**：对每一个候选框进行分类；**SVM**等；
**NMS非极大值抑制**：
1、将所有的框按类别划分，并剔除背景类，因为无需NMS；
2、对每个物体类中的边界框(B_BOX)，按照分类置信度降序排列；
3、在某一类中，选择置信度最高的边界框B_BOX1，将B_BOX1从输入列表中去除，并加入输出列表；
4、逐个计算B_BOX1与其余B_BOX2的交并比IoU，若IoU(B_BOX1,B_BOX2) > 阈值TH，则在输入去除B_BOX2；
5、重复步骤3~4，直到输入列表为空，完成一个物体类的遍历；
6、重复2~5，直到所有物体类的NMS处理完成；
7、输出列表，算法结束；
# 基于深度学习的目标检测算法
## 深度学习目标检测算法简介
目前基于深度学习的目标算法技术方向可以分为**基于anchor base**和**基于anchor free**的方法。anchor base和anchor free 的区别在于，有没有使用anchor来提取候选框。其中基于anchor base的技术路线中又可以分为two-stage和one-stage的方法。本章节会以RCNN系列网络为例介绍two-stage方法，以YOLO系列网络为例介绍one-stage方法、以CornerNet、ExtremeNet、CenterNet、FCOS为代表介绍anchor free 网络以及基于视频的目标检测网络。
## 基于anchor base的目标检测算法
### 基于two-stage的深度学习目标检测算法
#### RCNN系列
RCNN系列网络是two-stage网络的经典之作，其中RCNN网络首次将CNN网络引入目标检测领域，是CNN在目标检测领域的开山之作。下图是RCNN迭代示意图：
![RCNN算法改进方法图](./images/1648443748950.png)
##### [RCNN](https://arxiv.org/pdf/1311.2524v5.pdf)
![RCNN网络流程图](./images/1648359284957.png)
候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法）
特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN）
类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类
位置精修： 使用回归器精细修正候选框位置

**优点**
ss算法比滑动窗口更高效、精度更高；
**缺点**
ss算法还是很耗时；
2、四个模块基本是单独训练的，CNN使用预训练模型finetune、SVM重头训练、边框回归重头训练、微调困难；
##### Fast RCNN

##### Faster RCNN
### 基于one-stage的深度学习目标检测算法
#### YOLO系列
YOLO系列算法出自Joseph Redmon之手，可以说是one-stage目标检测算法的奠基之作。YOLO全称you only look once，意思是把将类别分类和框回归的任务进行统一。从YOLO 到YOLOv3，作者完成了YOLO系列网络的基础框架搭建，后续的网络大部分都是基于YOLOv3的网络做的一些修改。作者Joseph Redmon在2020年2月，在推文上宣布退出了CV领域（原因是军方邀请他观看了YOLOv3在军事无人机上的应用，作者认为这有违他的初衷）。在作者宣布退出CV界之后的4月和6月，YOLOv4和YOLOv5相续发表。
![logo](./images/1648444540673.png)
##### [YOLO](https://arxiv.org/pdf/1506.02640.pdf)
截屏2022-03-31 下午11.40.39![YIOLO流程示意图](./images/1648741292131.png)
算法流程：
1、把原图分成7✖️7的格子；
2、每个格子有2个候选框，但是只负责预测一个目标（框执行度以及每个类别的分数）；
3、再对7✖️7✖️2个格子，通过阈值删除置信度低的框，再使用NMS算法删除冗余框；

优点
1、速度快
2、背景误检率低；
3、通用能力强；
缺点
1、对小目标和密集目标检测能力差；
2、召回率低；
3、对边框的定位不够精准；

##### [YOLO9000](https://arxiv.org/pdf/1612.08242.pdf)
YOLO9000就是YOLOv2网络，在YOLO系列网络中起着承上启下的作用。下表是论文中列出的改进点以及每个改进点的提升：
截屏2022-04-01 上午12.10.43![YOLOv2改进点list](./images/1648743058964.png)
改进点：
1、增加了BN层；
2、使用高分辨率的分类器；
3、使用先验的anchor尺寸；
4、使用聚类的方式获取anchor的尺寸；
5、约束anchor的中心点位置；
6、提出passthrough层，增加细粒度特征；
7、使用多尺度的输入训练；
8、提出Darnet-19网络；
9、提出WordTree结构，支持9K+目标；

优点
1、大幅度提升了精度；
2、大幅度提升了检测的目标数量；

##### [YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf)
截屏2022-04-01 上午12.28.05![YOLO v3效果图](./images/1648744096687.png)
改进点：
1、多尺度预测 （引入FPN）。
2、更好的基础分类网络（darknet-53, 类似于ResNet引入残差结构）。
3、分类器不在使用Softmax，分类损失采用binary cross-entropy loss（二分类交叉损失熵）
##### [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf)
##### YOLOv5
#### SSD系列
## 基于anchor free的目标检测算法
## 基于视频的目标检测算法
### 双流网络
### 3DConv网络
### CNN+LSTM网络
### 图卷积网络
# 目标检测算法评价指标
